{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5e04bb-5645-4caf-a92b-07330ac577df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arango import ArangoClient\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# connexion à la base de données\n",
    "client = ArangoClient(hosts=\"http://localhost:8529\")\n",
    "sys_db = client.db('_system', username='root',password='root')\n",
    "db = client.db(\"text\", username=\"root\", password=\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85717952-fa95-4428-ab17-0be8dbcc0717",
   "metadata": {},
   "source": [
    "## graphe de similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f5efde-410c-49fb-99f2-0f78addc278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentences/doc0sent0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentences/doc0sent1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentences/doc0sent10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentences/doc0sent100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentences/doc0sent1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>sentences/doc3sent95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22947</th>\n",
       "      <td>sentences/doc3sent96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22948</th>\n",
       "      <td>sentences/doc3sent97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22949</th>\n",
       "      <td>sentences/doc3sent98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>sentences/doc3sent99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22951 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "0         sentences/doc0sent0\n",
       "1         sentences/doc0sent1\n",
       "2        sentences/doc0sent10\n",
       "3       sentences/doc0sent100\n",
       "4      sentences/doc0sent1000\n",
       "...                       ...\n",
       "22946    sentences/doc3sent95\n",
       "22947    sentences/doc3sent96\n",
       "22948    sentences/doc3sent97\n",
       "22949    sentences/doc3sent98\n",
       "22950    sentences/doc3sent99\n",
       "\n",
       "[22951 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ID_df = pd.DataFrame(list(\n",
    "    db.aql.execute('''\n",
    "    FOR doc in sentences\n",
    "    return doc._id\n",
    "    ''')\n",
    "    )\n",
    "                              )\n",
    "sentences_ID_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9a1488-0b71-4f97-9348-84b830afd1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentences/doc0sent0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ID_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf56309-67f0-47e3-8668-7413d089d122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence\n",
       "sentences/doc0sent0                                                     \u000130\n",
       "sentences/doc0sent1                                                     -on\n",
       "sentences/doc0sent10      1(2 1(4 and centre control correct credential ...\n",
       "sentences/doc0sent1000                                           and social\n",
       "sentences/doc0sent1001                           and based be been involved\n",
       "                                                ...                        \n",
       "sentences/doc3sent93                          cned dynamique employeur fois\n",
       "sentences/doc3sent94                                                  doute\n",
       "sentences/doc3sent96                                               fonction\n",
       "sentences/doc3sent97      activité attribut cadre dela enseignement entr...\n",
       "sentences/doc3sent98       destin donner douvrier enseigner formation forme\n",
       "Name: lemma, Length: 18693, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_from_sentences = pd.DataFrame(list(db.aql.execute('''for start_vertex in sentences\n",
    "        for v, e in inbound start_vertex is_from\n",
    "        filter e.type == 'lemmaToSent'\n",
    "        collect sent = e._to, lemmas = v.lemma into groups ={\n",
    "        \"sentence\" : e._to,\n",
    "        \"lemma\" : v.lemma\n",
    "        }\n",
    "        return {\"sentence\":sent,\n",
    "                \"lemma\":lemmas}\n",
    "                '''))).groupby('sentence')['lemma'].apply(' '.join)\n",
    "lemmas_from_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc2ea78-33eb-4877-9e5b-d1e57fd884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5736ab8-a2cb-483a-a783-1c5d0bdaf26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5)\n",
    "\n",
    "termDocMatrix  = vectorizer.fit_transform(lemmas_from_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da354987-f7ff-4ef1-8cdd-1d091787fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coOccurenceMatrix = termDocMatrix.T.dot(termDocMatrix)\n",
    "# retire les liens d'un nodeà lui même dnas la matrice\n",
    "coOccurenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21e63c-fd6a-47ce-9809-d5d785b27198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construction du graphe\n",
    "G = nx.from_scipy_sparse_array(coOccurenceMatrix,\n",
    "                                parallel_edges=False)\n",
    "\n",
    "# retire les arretes qui connectent un noeud à lui même \n",
    "\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "\n",
    "\n",
    "# définition de la position des noeuds par spatialisation fruchterman reingold\n",
    "\n",
    "FRL = nx.drawing.layout.fruchterman_reingold_layout(G)\n",
    "\n",
    "# kamada kawai\n",
    "# KMK = nx.drawing.layout.kamada_kawai_layout(G)\n",
    "\n",
    "for i in range(0,len(FRL)):\n",
    "    G.nodes[i]['pos'] = FRL[i]\n",
    "    \n",
    "\n",
    "\n",
    "def make_edge(x, y, width,scaledWidth):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: a tuple of the x from and to, in the form: tuple([x0, x1, None])\n",
    "        y: a tuple of the y from and to, in the form: tuple([y0, y1, None])\n",
    "        width: The width of the line\n",
    "\n",
    "    Returns:\n",
    "        a Scatter plot which represents a line between the two points given. \n",
    "    \"\"\"\n",
    "    return  go.Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                line=dict(width=width,color='#888'),\n",
    "                hoverinfo='none',\n",
    "                mode='lines',\n",
    "                opacity=scaledWidth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xTupleList = []\n",
    "yTupleList = []\n",
    "\n",
    "for ed in G.edges(): \n",
    "    xfrom = G.nodes()[ed[0]]['pos'][0]\n",
    "    yfrom = G.nodes()[ed[0]]['pos'][1]\n",
    "    \n",
    "    xto = G.nodes()[ed[1]]['pos'][0]\n",
    "    yto = G.nodes()[ed[1]]['pos'][1]\n",
    "    xTupleList.append((xfrom,xto,None))\n",
    "    yTupleList.append((yfrom,yto,None))\n",
    "\n",
    "widthList = np.array([G.edges[ed]['weight'] for ed in G.edges()])\n",
    "\n",
    "scaledWidthList = minmax_scale(widthList)\n",
    "\n",
    "\n",
    "\n",
    "edge_trace = [make_edge(x,y,w,sw) for x,y,w,sw in zip(xTupleList,yTupleList,widthList*0.5,scaledWidthList)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = G.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title=\"Nombre d'occurences\",\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "node_trace.marker.color = list(vectorizer.vocabulary_.values())\n",
    "node_trace.text = list(vectorizer.vocabulary_.keys())\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)', # transparent background\n",
    "    plot_bgcolor='rgba(0,0,0,0)', # transparent 2nd background\n",
    "    xaxis =  {'showgrid': False, 'zeroline': False}, # no gridlines\n",
    "    yaxis = {'showgrid': False, 'zeroline': False}, # no gridlines\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(layout = layout)\n",
    "\n",
    "# Add all edge traces\n",
    "for trace in edge_trace:\n",
    "    fig.add_trace(trace)# Add node trace\n",
    "fig.add_trace(node_trace)# Remove legend\n",
    "fig.update_layout(showlegend = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969429b-1edd-4a9d-92e8-c94a106a743f",
   "metadata": {},
   "source": [
    "## graphe syntagmatique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafb89e-9f4c-4a5a-9a01-a27d4789facf",
   "metadata": {},
   "source": [
    "sur la base d'un lemme, obtenir :\n",
    "- les tokens associés\n",
    "- les relations syntagmatiques de ces tokens\n",
    "- les tokens à l'issue de ces relations\n",
    "- la source de ces relations (pour l'instant le document mais se donner l'option d'ajouter d'autres variables à l'avenir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a13904-5eec-4ca3-994e-08952c7458f9",
   "metadata": {},
   "source": [
    "faire une requête de tous les tokens liés à un lemme avec un groupement par phrase\n",
    "- récupérer le doc depuis l'id de la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90abcb8c-471c-4cbb-ab6d-1a287c380818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_key': 'token1769',\n",
       "  '_id': 'tokens/token1769',\n",
       "  '_rev': '_eMbiN6W-A-',\n",
       "  'token': 'durée'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.collection('tokens').find({'token':\"durée\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc7ab980-f201-4aa2-992f-6f5913521835",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_of_interest = 'tokens/token2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c21dc709-e9b7-4736-b0e4-c54009a746ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th>_id</th>\n",
       "      <th>_from</th>\n",
       "      <th>_to</th>\n",
       "      <th>_rev</th>\n",
       "      <th>dep_relation</th>\n",
       "      <th>from_sentence_number</th>\n",
       "      <th>head_pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1318149</td>\n",
       "      <td>syntagmatic_link/1318149</td>\n",
       "      <td>tokens/token2</td>\n",
       "      <td>tokens/token3</td>\n",
       "      <td>_eMbiOAu--D</td>\n",
       "      <td>obj</td>\n",
       "      <td>doc0sent0</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1318146</td>\n",
       "      <td>syntagmatic_link/1318146</td>\n",
       "      <td>tokens/token0</td>\n",
       "      <td>tokens/token2</td>\n",
       "      <td>_eMbiOAu--A</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>doc0sent0</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _key                       _id          _from            _to  \\\n",
       "0  1318149  syntagmatic_link/1318149  tokens/token2  tokens/token3   \n",
       "1  1318146  syntagmatic_link/1318146  tokens/token0  tokens/token2   \n",
       "\n",
       "          _rev dep_relation from_sentence_number head_pos_tag  \n",
       "0  _eMbiOAu--D          obj            doc0sent0         VERB  \n",
       "1  _eMbiOAu--A        xcomp            doc0sent0         VERB  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(db.aql.execute(f'''\n",
    "                        FOR doc, connection in 1..1 any\n",
    "                        {'\"'+ token_of_interest + '\"'} syntagmatic_link\n",
    "                         return connection\n",
    "                    ''')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b6d91-2960-4a77-88a1-0a2cecd7e22d",
   "metadata": {},
   "source": [
    "## concordancier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4360fa0f-0d2f-44e7-b280-9c787029bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9df1cf97-6185-43ea-8e71-637f48c881c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_of_interest = ['point','vue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "57e87d8a-6321-40b2-85a2-3103e511ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tokens(tokens_list,doclist=[]):\n",
    "    \n",
    "    tokens_ids=  list(db.aql.execute(f'''let selection =  {tokens_list}\n",
    "for token in tokens \n",
    "filter token.token in selection\n",
    "return token._id'''))\n",
    "    \n",
    "    \n",
    "    dataframes_list = []\n",
    "    for word in tokens_ids:\n",
    "        content = (list(db.aql.execute(f\"\"\"for v, e in 1..1\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.content\"\"\")))\n",
    "\n",
    "        from_doc = (list(db.aql.execute(f\"\"\"for v, e in 2..2\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.doc_name\"\"\")))\n",
    "\n",
    "        dataframes_list.append(pd.DataFrame({'sentence':content,\n",
    "                                             'from_doc':from_doc}))\n",
    "        \n",
    "        df_recherche = pd.concat(dataframes_list).drop_duplicates()\n",
    "        \n",
    "        sentences_with_comparator = pd.concat([df_recherche,\n",
    "          pd.DataFrame({'sentence':[' '.join(tokens_list)],\n",
    "              'from_doc':['comparateur']})]\n",
    "         ).reset_index(drop=True)\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vector_text = vectorizer.fit_transform(sentences_with_comparator['sentence'])\n",
    "        similarity = cosine_similarity(vector_text[vector_text.shape[0]-1,:],vector_text)\n",
    "        sentences_with_comparator['similarity'] = similarity[0]\n",
    "        sentences_with_comparator = sentences_with_comparator.sort_values('similarity', ascending=False)\\\n",
    "                           .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        final_result = sentences_with_comparator[sentences_with_comparator['from_doc'] != 'comparateur']\n",
    "    if len(doclist) == 0:\n",
    "    \n",
    "        return final_result\n",
    "    elif len(doclist) > 0: \n",
    "        return final_result[final_result['from_doc'].isin(doclist)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13376590-d8d0-496f-acf1-722a86456866",
   "metadata": {},
   "source": [
    "### text version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d0004920-37ff-4d27-a99f-f2d7d4461615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tokens(tokens_list,doclist=[]):\n",
    "    \n",
    "    tokens_ids=  list(db.aql.execute(f'''let selection =  {tokens_list}\n",
    "for token in tokens \n",
    "filter token.token in selection\n",
    "return token._id'''))\n",
    "    \n",
    "    \n",
    "    dataframes_list = []\n",
    "    for word in tokens_ids:\n",
    "        content = (list(db.aql.execute(f\"\"\"for v, e in 1..1\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.content\"\"\")))\n",
    "\n",
    "        from_doc = (list(db.aql.execute(f\"\"\"for v, e in 2..2\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.doc_name\"\"\")))\n",
    "\n",
    "        dataframes_list.append(pd.DataFrame({'sentence':content,\n",
    "                                             'from_doc':from_doc}))\n",
    "        \n",
    "        df_recherche = pd.concat(dataframes_list).drop_duplicates()\n",
    "        \n",
    "        sentences_with_comparator = pd.concat([df_recherche,\n",
    "          pd.DataFrame({'sentence':[' '.join(tokens_list)],\n",
    "              'from_doc':['comparateur']})]\n",
    "         ).reset_index(drop=True)\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vector_text = vectorizer.fit_transform(sentences_with_comparator['sentence'])\n",
    "        similarity = cosine_similarity(vector_text[vector_text.shape[0]-1,:],vector_text)\n",
    "        sentences_with_comparator['similarity'] = similarity[0]\n",
    "        sentences_with_comparator = sentences_with_comparator.sort_values('similarity', ascending=False)\\\n",
    "                           .reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        final_result = sentences_with_comparator[sentences_with_comparator['from_doc'] != 'comparateur']\n",
    "    if len(doclist) == 0:\n",
    "    \n",
    "        final_result = final_result\n",
    "    elif len(doclist) > 0: \n",
    "        final_result =  final_result[final_result['from_doc'].isin(doclist)]\n",
    "        \n",
    "    \n",
    "    list_sentences = []\n",
    "    for sentence, doc, similarity in zip(final_result['sentence'],\n",
    "                                      final_result['from_doc'],\n",
    "                                      final_result['similarity']):\n",
    "        list_sentences.append(f'Tiré du document : {doc} | Prévalence dans la phrase : {similarity} \\n __ \\n \\n {sentence} \\n __ \\n \\n')\n",
    "    return ' '.join(list_sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3acf110-8f75-4c0c-8a09-f58835082ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6585e0-8ef6-4634-a53e-cf1b4d3bf891",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "02423e67-e1f4-4d17-9b93-820da1a9b30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiré du document : lomonaco 1.txt | Prévalence dans la phrase : 0.20122345559870214 \n",
      " __ \n",
      " \n",
      " Traité de psychologie sociale \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.19400130669475918 \n",
      " __ \n",
      " \n",
      " Intégration sociale Resultats \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.16654433087118806 \n",
      " __ \n",
      " \n",
      " Plus grande valeur sociale \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.15871111879061645 \n",
      " __ \n",
      " \n",
      " Les explications internes permettent une valorisation sociale. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.14558004690914536 \n",
      " __ \n",
      " \n",
      " La norme d’internalité est une norme sociale. \n",
      " __ \n",
      " \n",
      " Tiré du document : différentielle.txt | Prévalence dans la phrase : 0.13138607847157155 \n",
      " __ \n",
      " \n",
      "  Intelligence : caractéristiques d’adaptation (environnementale, sociale…) \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.12738816870944822 \n",
      " __ \n",
      " \n",
      " Jugés plus positivement sur l’intégration sociale \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.11962006065599823 \n",
      " __ \n",
      " \n",
      " Le groupe est un objet essentiel de la psychologie sociale \n",
      " __ \n",
      " \n",
      " Tiré du document : lomonaco 1.txt | Prévalence dans la phrase : 0.10692343359069974 \n",
      " __ \n",
      " \n",
      " Explication causale : un des domaines de prédilection de la psycho sociale   \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 1.txt | Prévalence dans la phrase : 0.1017113252165419 \n",
      " __ \n",
      " \n",
      " Elle est très importante en psychologie sociale et concerne les comportements. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.09968882732013623 \n",
      " __ \n",
      " \n",
      " Permet de produire une image positive en situation de comparaison sociale. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.09891183895221599 \n",
      " __ \n",
      " \n",
      " Plusieurs auteurs considèrent que l’erreur fondamentale d’attribution est une norme sociale \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.09234261530569633 \n",
      " __ \n",
      " \n",
      " ceux répondant de façon contre normative en ayant conscience de la valorisation sociale des explications causales internes : \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.09046427757432944 \n",
      " __ \n",
      " \n",
      " La norme repose toujours sur une attribution de valeur sociale qui fonde son existence. \n",
      " __ \n",
      " \n",
      " Tiré du document : lomonaco 1.txt | Prévalence dans la phrase : 0.08869766274889644 \n",
      " __ \n",
      " \n",
      "  L’attribution causale se trouve donc être un domaine très important dans la psychologie sociale. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.08859356787195564 \n",
      " __ \n",
      " \n",
      " ceux répondant de façon normative à un questionnaire d’internalité et sont conscients de la valorisation sociale des explications internes : \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.08473497213245072 \n",
      " __ \n",
      " \n",
      " La norme sociale d’internalité est valorisant, la posséder est quelque chose de valorisé socialement. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.08312614586994503 \n",
      " __ \n",
      " \n",
      " ceux répondant contre normativement et n’ayant aucune connaissance de la valorisation sociale des explications causales internes : vrai externes   \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.0828955146385642 \n",
      " __ \n",
      " \n",
      " La norme fait l’objet d’un apprentissage social ou d’une transmission sociale dès la petite enfance \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.0810651430329644 \n",
      " __ \n",
      " \n",
      " ceux répondant de façon normative mas n’ont pas connaissance de la valorisation sociale des explications causales internes : vrais internes \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.08083517867246547 \n",
      " __ \n",
      " \n",
      " Chez les adultes, le choix d’une explication interne participe à une valorisation sociale (dans notre société) \n",
      " __ \n",
      " \n",
      " Tiré du document : lomonaco 1.txt | Prévalence dans la phrase : 0.07459892007967492 \n",
      " __ \n",
      " \n",
      " L’attribution causale se trouve donc au centre de la psychologie sociale  Un même acte peut donner lieu à différentes explications   \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.07427519012569521 \n",
      " __ \n",
      " \n",
      " Enfant adolescent ou adulte ont une bonne perception de la valorisation sociale des explications internes des conduites et des renforcements : \n",
      " __ \n",
      " \n",
      " Tiré du document : différentielle.txt | Prévalence dans la phrase : 0.07353285934498888 \n",
      " __ \n",
      " \n",
      " Face à cette tâche, on doit apporter une réponse, que ce soit une tâche cognitive, sociale… \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.06459859153179892 \n",
      " __ \n",
      " \n",
      " Norme d’internalité : la valorisation sociale des explications des comportements et des renforcements qui accentuent le poids de l’acteur comme facteur causal (Beauvois et Dubois) \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 3.txt | Prévalence dans la phrase : 0.05651093402633781 \n",
      " __ \n",
      " \n",
      " Py et Somat postulent l’existence d’une clairvoyance normative rendant compte du degré de perception qu’ont les individus du caractère normatif ou de valorisation sociale associées aux explications causales internes. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.055748736544014 \n",
      " __ \n",
      " \n",
      " L’erreur ultime d’attribution aurait pour fonction de permettre aux membres du groupe de se construire une identité sociale positive On attribue des causes internes aux comportements positifs de l’endogroupe \n",
      " __ \n",
      " \n",
      " Tiré du document : différentielle.txt | Prévalence dans la phrase : 0.04622069202727254 \n",
      " __ \n",
      " \n",
      " 2ème aspect fondamental : la confrontation à une tâche  toute situation à laquelle nous sommes confrontées (personnelle, sociale…) peut être considérée comme une tâche de traitement de l’information : tâche  traitement de l’information  réponse. \n",
      " __ \n",
      " \n",
      " Tiré du document : girandola 2.txt | Prévalence dans la phrase : 0.03823679795703846 \n",
      " __ \n",
      " \n",
      " Cette intériorisation se fait par le biais de la socialisation En même temps que l’enfant apprend ce qui est permis et ce qui est défendu, il assimile les valeurs de sa famille, de sa classe sociale, de la société si bien que les évènements normatifs finissent par devenir naturels. \n",
      " __ \n",
      " \n",
      " Tiré du document : différentielle.txt | Prévalence dans la phrase : 0.03755149823300164 \n",
      " __ \n",
      " \n",
      " « En aidant [les individus] à rendre plus intelligibles les univers qui entourent (le monde physique, l’univers du langage, l’univers des idées et des émotions, celui des apprentissages, des relations sociale, etc.) on les aide à s’ajuster aux exigences, aux contraintes et aux potentialités de ceux-ci. \n",
      " __ \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(search_tokens(['sociale']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3d53ee5c-5b73-4225-97c0-8e6af44617cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "094aee1d-97c7-45be-9a3c-acb5eed4fc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6c1e462a-d11e-4b7a-a8d8-d04a327602e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "83e0d2fc-3f45-437b-8bff-03bd21a384c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>from_doc</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traité de psychologie sociale</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.201223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intégration sociale Resultats</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.194001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plus grande valeur sociale</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.166544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Les explications internes permettent une valor...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.158711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La norme d’internalité est une norme sociale.</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.145580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intelligence : caractéristiques d’adaptation ...</td>\n",
       "      <td>différentielle.txt</td>\n",
       "      <td>0.131386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jugés plus positivement sur l’intégration sociale</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.127388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Le groupe est un objet essentiel de la psychol...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.119620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Explication causale : un des domaines de prédi...</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.106923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elle est très importante en psychologie social...</td>\n",
       "      <td>girandola 1.txt</td>\n",
       "      <td>0.101711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Permet de produire une image positive en situa...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.099689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Plusieurs auteurs considèrent que l’erreur fon...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.098912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ceux répondant de façon contre normative en ay...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.092343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>La norme repose toujours sur une attribution d...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.090464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>L’attribution causale se trouve donc être un ...</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.088698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ceux répondant de façon normative à un questio...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.088594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>La norme sociale d’internalité est valorisant,...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.084735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ceux répondant contre normativement et n’ayant...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.083126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>La norme fait l’objet d’un apprentissage socia...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.082896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ceux répondant de façon normative mas n’ont pa...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.081065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chez les adultes, le choix d’une explication i...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.080835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>L’attribution causale se trouve donc au centre...</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.074599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Enfant adolescent ou adulte ont une bonne perc...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.074275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Face à cette tâche, on doit apporter une répon...</td>\n",
       "      <td>différentielle.txt</td>\n",
       "      <td>0.073533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Norme d’internalité : la valorisation sociale ...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.064599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Py et Somat postulent l’existence d’une clairv...</td>\n",
       "      <td>girandola 3.txt</td>\n",
       "      <td>0.056511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>L’erreur ultime d’attribution aurait pour fonc...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.055749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2ème aspect fondamental : la confrontation à u...</td>\n",
       "      <td>différentielle.txt</td>\n",
       "      <td>0.046221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cette intériorisation se fait par le biais de ...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.038237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>« En aidant [les individus] à rendre plus inte...</td>\n",
       "      <td>différentielle.txt</td>\n",
       "      <td>0.037551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence            from_doc  \\\n",
       "1                       Traité de psychologie sociale      lomonaco 1.txt   \n",
       "2                       Intégration sociale Resultats     girandola 3.txt   \n",
       "3                          Plus grande valeur sociale     girandola 2.txt   \n",
       "4   Les explications internes permettent une valor...     girandola 3.txt   \n",
       "5       La norme d’internalité est une norme sociale.     girandola 2.txt   \n",
       "6    Intelligence : caractéristiques d’adaptation ...  différentielle.txt   \n",
       "7   Jugés plus positivement sur l’intégration sociale     girandola 3.txt   \n",
       "8   Le groupe est un objet essentiel de la psychol...     girandola 2.txt   \n",
       "9   Explication causale : un des domaines de prédi...      lomonaco 1.txt   \n",
       "10  Elle est très importante en psychologie social...     girandola 1.txt   \n",
       "11  Permet de produire une image positive en situa...     girandola 2.txt   \n",
       "12  Plusieurs auteurs considèrent que l’erreur fon...     girandola 2.txt   \n",
       "13  ceux répondant de façon contre normative en ay...     girandola 3.txt   \n",
       "14  La norme repose toujours sur une attribution d...     girandola 2.txt   \n",
       "15   L’attribution causale se trouve donc être un ...      lomonaco 1.txt   \n",
       "16  ceux répondant de façon normative à un questio...     girandola 3.txt   \n",
       "17  La norme sociale d’internalité est valorisant,...     girandola 2.txt   \n",
       "18  ceux répondant contre normativement et n’ayant...     girandola 3.txt   \n",
       "19  La norme fait l’objet d’un apprentissage socia...     girandola 2.txt   \n",
       "20  ceux répondant de façon normative mas n’ont pa...     girandola 3.txt   \n",
       "21  Chez les adultes, le choix d’une explication i...     girandola 3.txt   \n",
       "22  L’attribution causale se trouve donc au centre...      lomonaco 1.txt   \n",
       "23  Enfant adolescent ou adulte ont une bonne perc...     girandola 3.txt   \n",
       "24  Face à cette tâche, on doit apporter une répon...  différentielle.txt   \n",
       "25  Norme d’internalité : la valorisation sociale ...     girandola 2.txt   \n",
       "26  Py et Somat postulent l’existence d’une clairv...     girandola 3.txt   \n",
       "27  L’erreur ultime d’attribution aurait pour fonc...     girandola 2.txt   \n",
       "28  2ème aspect fondamental : la confrontation à u...  différentielle.txt   \n",
       "29  Cette intériorisation se fait par le biais de ...     girandola 2.txt   \n",
       "30  « En aidant [les individus] à rendre plus inte...  différentielle.txt   \n",
       "\n",
       "    similarity  \n",
       "1     0.201223  \n",
       "2     0.194001  \n",
       "3     0.166544  \n",
       "4     0.158711  \n",
       "5     0.145580  \n",
       "6     0.131386  \n",
       "7     0.127388  \n",
       "8     0.119620  \n",
       "9     0.106923  \n",
       "10    0.101711  \n",
       "11    0.099689  \n",
       "12    0.098912  \n",
       "13    0.092343  \n",
       "14    0.090464  \n",
       "15    0.088698  \n",
       "16    0.088594  \n",
       "17    0.084735  \n",
       "18    0.083126  \n",
       "19    0.082896  \n",
       "20    0.081065  \n",
       "21    0.080835  \n",
       "22    0.074599  \n",
       "23    0.074275  \n",
       "24    0.073533  \n",
       "25    0.064599  \n",
       "26    0.056511  \n",
       "27    0.055749  \n",
       "28    0.046221  \n",
       "29    0.038237  \n",
       "30    0.037551  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtv = search_tokens(['sociale'])\n",
    "wtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "391d2b81-e77f-4755-b44d-02fdc61f677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_of_interest = ['face','tâche']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "40ab2825-8269-43de-b41d-8409685e855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_index = []\n",
    "for sentence, index in zip(wtv['sentence'],wtv.index):\n",
    "    if all(word.lower() in sentence.lower() for word in words_of_interest):\n",
    "        match_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d734ebcd-2b08-4c52-99d9-578bae4f1e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "032dbd60-e577-474e-84ba-8de2f52dcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tokens(tokens_list,doclist=[]):\n",
    "    \n",
    "    tokens_ids=  list(db.aql.execute(f'''let selection =  {tokens_list}\n",
    "for token in tokens \n",
    "filter token.token in selection\n",
    "return token._id'''))\n",
    "    \n",
    "    \n",
    "    dataframes_list = []\n",
    "    for word in tokens_ids:\n",
    "        content = (list(db.aql.execute(f\"\"\"for v, e in 1..1\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.content\"\"\")))\n",
    "\n",
    "        from_doc = (list(db.aql.execute(f\"\"\"for v, e in 2..2\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.doc_name\"\"\")))\n",
    "\n",
    "        dataframes_list.append(pd.DataFrame({'sentence':content,\n",
    "                                             'from_doc':from_doc}))\n",
    "        \n",
    "        df_recherche = pd.concat(dataframes_list).drop_duplicates()\n",
    "        \n",
    "        sentences_with_comparator = pd.concat([df_recherche,\n",
    "          pd.DataFrame({'sentence':[' '.join(tokens_list)],\n",
    "              'from_doc':['comparateur']})]\n",
    "         ).reset_index(drop=True)\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vector_text = vectorizer.fit_transform(sentences_with_comparator['sentence'])\n",
    "        similarity = cosine_similarity(vector_text[vector_text.shape[0]-1,:],vector_text)\n",
    "        sentences_with_comparator['similarity'] = similarity[0]\n",
    "        sentences_with_comparator = sentences_with_comparator.sort_values('similarity', ascending=False)\\\n",
    "                           .reset_index(drop=True)\n",
    "             \n",
    "        \n",
    "        \n",
    "        sentences = sentences_with_comparator[sentences_with_comparator['from_doc'] != 'comparateur']\n",
    "        \n",
    "        # réduit le résultat à seulement les documents où tous les mots apparaissent\n",
    "        match_index = []\n",
    "        for sentence, index in zip(sentences['sentence'],sentences.index):\n",
    "            if all(word.lower() in sentence.lower() for word in tokens_list):\n",
    "                match_index.append(index)\n",
    "        final_result = sentences.loc[match_index,:]\n",
    "        \n",
    "    \n",
    "    if len(doclist) == 0:\n",
    "        return final_result\n",
    "    \n",
    "    elif len(doclist) > 0: \n",
    "        return final_result[final_result['from_doc'].isin(doclist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "44ba4704-6a13-4639-8884-1c143d8331f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>from_doc</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plus grande valeur sociale</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.166544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La norme d’internalité est une norme sociale.</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.145580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Le groupe est un objet essentiel de la psychol...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.119620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elle est très importante en psychologie social...</td>\n",
       "      <td>girandola 1.txt</td>\n",
       "      <td>0.101711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Permet de produire une image positive en situa...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.099689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Plusieurs auteurs considèrent que l’erreur fon...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.098912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>La norme repose toujours sur une attribution d...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.090464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>La norme sociale d’internalité est valorisant,...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.084735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>La norme fait l’objet d’un apprentissage socia...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.082896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Norme d’internalité : la valorisation sociale ...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.064599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>L’erreur ultime d’attribution aurait pour fonc...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.055749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cette intériorisation se fait par le biais de ...</td>\n",
       "      <td>girandola 2.txt</td>\n",
       "      <td>0.038237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence         from_doc  \\\n",
       "3                          Plus grande valeur sociale  girandola 2.txt   \n",
       "5       La norme d’internalité est une norme sociale.  girandola 2.txt   \n",
       "8   Le groupe est un objet essentiel de la psychol...  girandola 2.txt   \n",
       "10  Elle est très importante en psychologie social...  girandola 1.txt   \n",
       "11  Permet de produire une image positive en situa...  girandola 2.txt   \n",
       "12  Plusieurs auteurs considèrent que l’erreur fon...  girandola 2.txt   \n",
       "14  La norme repose toujours sur une attribution d...  girandola 2.txt   \n",
       "17  La norme sociale d’internalité est valorisant,...  girandola 2.txt   \n",
       "19  La norme fait l’objet d’un apprentissage socia...  girandola 2.txt   \n",
       "25  Norme d’internalité : la valorisation sociale ...  girandola 2.txt   \n",
       "27  L’erreur ultime d’attribution aurait pour fonc...  girandola 2.txt   \n",
       "29  Cette intériorisation se fait par le biais de ...  girandola 2.txt   \n",
       "\n",
       "    similarity  \n",
       "3     0.166544  \n",
       "5     0.145580  \n",
       "8     0.119620  \n",
       "10    0.101711  \n",
       "11    0.099689  \n",
       "12    0.098912  \n",
       "14    0.090464  \n",
       "17    0.084735  \n",
       "19    0.082896  \n",
       "25    0.064599  \n",
       "27    0.055749  \n",
       "29    0.038237  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = search_tokens(['sociale'],['girandola 1.txt','girandola 2.txt'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7d1c8-819d-4498-be25-5f19bf46a2d8",
   "metadata": {},
   "source": [
    "## fonction trop grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9f13517b-8283-4e0c-b5bb-7ea53b14b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_tokens(tokens_list,doclist=[]):\n",
    "    \n",
    "    tokens_ids=  list(db.aql.execute(f'''let selection =  {tokens_list}\n",
    "for token in tokens \n",
    "filter token.token in selection\n",
    "return token._id'''))\n",
    "    \n",
    "    \n",
    "    dataframes_list = []\n",
    "    for word in tokens_ids:\n",
    "        content = (list(db.aql.execute(f\"\"\"for v, e in 1..1\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.content\"\"\")))\n",
    "\n",
    "        from_doc = (list(db.aql.execute(f\"\"\"for v, e in 2..2\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    return v.doc_name\"\"\")))\n",
    "\n",
    "        dataframes_list.append(pd.DataFrame({'sentence':content,\n",
    "                                             'from_doc':from_doc}))\n",
    "        \n",
    "        df_recherche = pd.concat(dataframes_list).drop_duplicates()\n",
    "        \n",
    "        sentences_with_comparator = pd.concat([df_recherche,\n",
    "          pd.DataFrame({'sentence':[' '.join(tokens_list)],\n",
    "              'from_doc':['comparateur']})]\n",
    "         ).reset_index(drop=True)\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vector_text = vectorizer.fit_transform(sentences_with_comparator['sentence'])\n",
    "        similarity = cosine_similarity(vector_text[vector_text.shape[0]-1,:],vector_text)\n",
    "        sentences_with_comparator['similarity'] = similarity[0]\n",
    "        sentences_with_comparator = sentences_with_comparator.sort_values('similarity', ascending=False)\\\n",
    "                           .reset_index(drop=True)\n",
    "        sentences = sentences_with_comparator[sentences_with_comparator['from_doc'] != 'comparateur']\n",
    "          # réduit le résultat à seulement les documents où tous les mots apparaissent\n",
    "        match_index = []\n",
    "        for sentence, index in zip(sentences['sentence'],sentences.index):\n",
    "            if all(word.lower() in sentence.lower() for word in tokens_list):\n",
    "                match_index.append(index)\n",
    "        if len(match_index) == 0:\n",
    "            return ('not found')\n",
    "        elif len(match_index) > 0:\n",
    "            final_result = sentences.loc[match_index,:]\n",
    "            return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "dad68719-561b-4701-8273-49e2486e2ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(search_tokens(['attribn'],['lomonaco 2.txt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5661644-179b-4182-9544-d42e5a861125",
   "metadata": {},
   "source": [
    "# todo :\n",
    "construire une requette qui récupère seulement les textes où tous les mots sont présents pas seulement un d'entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87df2a4-fe78-46d1-91f2-31d6ca23742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(liste_words,black_liste_words=[]):\n",
    "    # On récupère dans la liste des indicateurs ceux qui contiennent tous les mots clés données en argument\n",
    "    filtered_list = [x for x in indicNames if\n",
    "              all(y in x.lower() for y in liste_words) and\n",
    "               not any(z in x.lower() for z in black_liste_words)] # avec option de retirer certains termes indésirés\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0b245e83-bcf1-4d0c-9f05-a9d27714a7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'boi']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def search(input1,input2):\n",
    "    \n",
    "    if input1 is None and input2 is None:\n",
    "        return 'En attente de termes de recherche.'\n",
    "    elif input1 is not None and input2 is None:\n",
    "        df_search = search_tokens(input1.split(' '))\n",
    "        if df_search is None :\n",
    "            return \"Mot non trouvé dans le corpus.\"\n",
    "        elif df_search.shape[0] == 0:\n",
    "            return \"Un des mots recherchés est absent du corpus.\"\n",
    "        elif df_search.shape[0] > 0:\n",
    "            return df_to_text(df_search)\n",
    "    elif input1 is not None and input2 is not None:\n",
    "        df_search = search_tokens(input1.split(' '))\n",
    "        if df_search is None :\n",
    "            return \"Mot non trouvé dans le corpus.\"\n",
    "        elif df_search.shape[0] == 0:\n",
    "            return \"Un des mots recherchés est absent du corpus.\"\n",
    "        elif df_search.shape[0] > 0:\n",
    "            df_search_filtered = filter_on_docs(df_search,input2)\n",
    "            \n",
    "            if df_search_filtered is None:\n",
    "                return 'Terme absent dans les documents sélectionnés.'\n",
    "                \n",
    "            elif df_search_filtered is not None :\n",
    "                return df_to_text(df_search_filtered)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
