{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5e04bb-5645-4caf-a92b-07330ac577df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arango import ArangoClient\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# connexion à la base de données\n",
    "client = ArangoClient(hosts=\"http://localhost:8529\")\n",
    "sys_db = client.db('_system', username='root',password='root')\n",
    "db = client.db(\"text\", username=\"root\", password=\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85717952-fa95-4428-ab17-0be8dbcc0717",
   "metadata": {},
   "source": [
    "## graphe de similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f5efde-410c-49fb-99f2-0f78addc278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentences/doc0sent0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentences/doc0sent1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentences/doc0sent10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentences/doc0sent100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentences/doc0sent1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22946</th>\n",
       "      <td>sentences/doc3sent95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22947</th>\n",
       "      <td>sentences/doc3sent96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22948</th>\n",
       "      <td>sentences/doc3sent97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22949</th>\n",
       "      <td>sentences/doc3sent98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>sentences/doc3sent99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22951 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "0         sentences/doc0sent0\n",
       "1         sentences/doc0sent1\n",
       "2        sentences/doc0sent10\n",
       "3       sentences/doc0sent100\n",
       "4      sentences/doc0sent1000\n",
       "...                       ...\n",
       "22946    sentences/doc3sent95\n",
       "22947    sentences/doc3sent96\n",
       "22948    sentences/doc3sent97\n",
       "22949    sentences/doc3sent98\n",
       "22950    sentences/doc3sent99\n",
       "\n",
       "[22951 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ID_df = pd.DataFrame(list(\n",
    "    db.aql.execute('''\n",
    "    FOR doc in sentences\n",
    "    return doc._id\n",
    "    ''')\n",
    "    )\n",
    "                              )\n",
    "sentences_ID_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9a1488-0b71-4f97-9348-84b830afd1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentences/doc0sent0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ID_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf56309-67f0-47e3-8668-7413d089d122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence\n",
       "sentences/doc0sent0                                                     \u000130\n",
       "sentences/doc0sent1                                                     -on\n",
       "sentences/doc0sent10      1(2 1(4 and centre control correct credential ...\n",
       "sentences/doc0sent1000                                           and social\n",
       "sentences/doc0sent1001                           and based be been involved\n",
       "                                                ...                        \n",
       "sentences/doc3sent93                          cned dynamique employeur fois\n",
       "sentences/doc3sent94                                                  doute\n",
       "sentences/doc3sent96                                               fonction\n",
       "sentences/doc3sent97      activité attribut cadre dela enseignement entr...\n",
       "sentences/doc3sent98       destin donner douvrier enseigner formation forme\n",
       "Name: lemma, Length: 18693, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_from_sentences = pd.DataFrame(list(db.aql.execute('''for start_vertex in sentences\n",
    "        for v, e in inbound start_vertex is_from\n",
    "        filter e.type == 'lemmaToSent'\n",
    "        collect sent = e._to, lemmas = v.lemma into groups ={\n",
    "        \"sentence\" : e._to,\n",
    "        \"lemma\" : v.lemma\n",
    "        }\n",
    "        return {\"sentence\":sent,\n",
    "                \"lemma\":lemmas}\n",
    "                '''))).groupby('sentence')['lemma'].apply(' '.join)\n",
    "lemmas_from_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc2ea78-33eb-4877-9e5b-d1e57fd884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='browser'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5736ab8-a2cb-483a-a783-1c5d0bdaf26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5)\n",
    "\n",
    "termDocMatrix  = vectorizer.fit_transform(lemmas_from_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da354987-f7ff-4ef1-8cdd-1d091787fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coOccurenceMatrix = termDocMatrix.T.dot(termDocMatrix)\n",
    "# retire les liens d'un nodeà lui même dnas la matrice\n",
    "coOccurenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21e63c-fd6a-47ce-9809-d5d785b27198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construction du graphe\n",
    "G = nx.from_scipy_sparse_array(coOccurenceMatrix,\n",
    "                                parallel_edges=False)\n",
    "\n",
    "# retire les arretes qui connectent un noeud à lui même \n",
    "\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "\n",
    "\n",
    "# définition de la position des noeuds par spatialisation fruchterman reingold\n",
    "\n",
    "FRL = nx.drawing.layout.fruchterman_reingold_layout(G)\n",
    "\n",
    "# kamada kawai\n",
    "# KMK = nx.drawing.layout.kamada_kawai_layout(G)\n",
    "\n",
    "for i in range(0,len(FRL)):\n",
    "    G.nodes[i]['pos'] = FRL[i]\n",
    "    \n",
    "\n",
    "\n",
    "def make_edge(x, y, width,scaledWidth):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: a tuple of the x from and to, in the form: tuple([x0, x1, None])\n",
    "        y: a tuple of the y from and to, in the form: tuple([y0, y1, None])\n",
    "        width: The width of the line\n",
    "\n",
    "    Returns:\n",
    "        a Scatter plot which represents a line between the two points given. \n",
    "    \"\"\"\n",
    "    return  go.Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                line=dict(width=width,color='#888'),\n",
    "                hoverinfo='none',\n",
    "                mode='lines',\n",
    "                opacity=scaledWidth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xTupleList = []\n",
    "yTupleList = []\n",
    "\n",
    "for ed in G.edges(): \n",
    "    xfrom = G.nodes()[ed[0]]['pos'][0]\n",
    "    yfrom = G.nodes()[ed[0]]['pos'][1]\n",
    "    \n",
    "    xto = G.nodes()[ed[1]]['pos'][0]\n",
    "    yto = G.nodes()[ed[1]]['pos'][1]\n",
    "    xTupleList.append((xfrom,xto,None))\n",
    "    yTupleList.append((yfrom,yto,None))\n",
    "\n",
    "widthList = np.array([G.edges[ed]['weight'] for ed in G.edges()])\n",
    "\n",
    "scaledWidthList = minmax_scale(widthList)\n",
    "\n",
    "\n",
    "\n",
    "edge_trace = [make_edge(x,y,w,sw) for x,y,w,sw in zip(xTupleList,yTupleList,widthList*0.5,scaledWidthList)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = G.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title=\"Nombre d'occurences\",\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "node_trace.marker.color = list(vectorizer.vocabulary_.values())\n",
    "node_trace.text = list(vectorizer.vocabulary_.keys())\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)', # transparent background\n",
    "    plot_bgcolor='rgba(0,0,0,0)', # transparent 2nd background\n",
    "    xaxis =  {'showgrid': False, 'zeroline': False}, # no gridlines\n",
    "    yaxis = {'showgrid': False, 'zeroline': False}, # no gridlines\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(layout = layout)\n",
    "\n",
    "# Add all edge traces\n",
    "for trace in edge_trace:\n",
    "    fig.add_trace(trace)# Add node trace\n",
    "fig.add_trace(node_trace)# Remove legend\n",
    "fig.update_layout(showlegend = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969429b-1edd-4a9d-92e8-c94a106a743f",
   "metadata": {},
   "source": [
    "## graphe syntagmatique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafb89e-9f4c-4a5a-9a01-a27d4789facf",
   "metadata": {},
   "source": [
    "sur la base d'un lemme, obtenir :\n",
    "- les tokens associés\n",
    "- les relations syntagmatiques de ces tokens\n",
    "- les tokens à l'issue de ces relations\n",
    "- la source de ces relations (pour l'instant le document mais se donner l'option d'ajouter d'autres variables à l'avenir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a13904-5eec-4ca3-994e-08952c7458f9",
   "metadata": {},
   "source": [
    "faire une requête de tous les tokens liés à un lemme avec un groupement par phrase\n",
    "- récupérer le doc depuis l'id de la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90abcb8c-471c-4cbb-ab6d-1a287c380818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_key': 'token1769',\n",
       "  '_id': 'tokens/token1769',\n",
       "  '_rev': '_eMbiN6W-A-',\n",
       "  'token': 'durée'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.collection('tokens').find({'token':\"durée\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc7ab980-f201-4aa2-992f-6f5913521835",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_of_interest = 'tokens/token2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c21dc709-e9b7-4736-b0e4-c54009a746ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_key</th>\n",
       "      <th>_id</th>\n",
       "      <th>_from</th>\n",
       "      <th>_to</th>\n",
       "      <th>_rev</th>\n",
       "      <th>dep_relation</th>\n",
       "      <th>from_sentence_number</th>\n",
       "      <th>head_pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1318149</td>\n",
       "      <td>syntagmatic_link/1318149</td>\n",
       "      <td>tokens/token2</td>\n",
       "      <td>tokens/token3</td>\n",
       "      <td>_eMbiOAu--D</td>\n",
       "      <td>obj</td>\n",
       "      <td>doc0sent0</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1318146</td>\n",
       "      <td>syntagmatic_link/1318146</td>\n",
       "      <td>tokens/token0</td>\n",
       "      <td>tokens/token2</td>\n",
       "      <td>_eMbiOAu--A</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>doc0sent0</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _key                       _id          _from            _to  \\\n",
       "0  1318149  syntagmatic_link/1318149  tokens/token2  tokens/token3   \n",
       "1  1318146  syntagmatic_link/1318146  tokens/token0  tokens/token2   \n",
       "\n",
       "          _rev dep_relation from_sentence_number head_pos_tag  \n",
       "0  _eMbiOAu--D          obj            doc0sent0         VERB  \n",
       "1  _eMbiOAu--A        xcomp            doc0sent0         VERB  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(db.aql.execute(f'''\n",
    "                        FOR doc, connection in 1..1 any\n",
    "                        {'\"'+ token_of_interest + '\"'} syntagmatic_link\n",
    "                         return connection\n",
    "                    ''')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b6d91-2960-4a77-88a1-0a2cecd7e22d",
   "metadata": {},
   "source": [
    "## concordancier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4360fa0f-0d2f-44e7-b280-9c787029bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9df1cf97-6185-43ea-8e71-637f48c881c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_of_interest = ['point','vue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f60aab87-5d4a-4a3d-b23a-796be2026c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tokens(tokens_list,doclist=[]):\n",
    "    \n",
    "    tokens_ids=  list(db.aql.execute(f'''let selection =  {tokens_list}\n",
    "for token in tokens \n",
    "filter token.token in selection\n",
    "return token._id'''))\n",
    "    \n",
    "    \n",
    "    dataframes_list = []\n",
    "    for word in tokens_ids:\n",
    "        content = (list(db.aql.execute(f\"\"\"for v, e in 1..1\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    filter v.content in {tokens_list}\n",
    "    return v.content\"\"\")))\n",
    "\n",
    "        from_doc = (list(db.aql.execute(f\"\"\"for v, e in 2..2\n",
    "    outbound '{word}'\n",
    "    is_from\n",
    "    filter v.content in {tokens_list}\n",
    "    return v.doc_name\"\"\")))\n",
    "\n",
    "        dataframes_list.append(pd.DataFrame({'sentence':content,\n",
    "                                             'from_doc':from_doc}))\n",
    "        \n",
    "        df_recherche = pd.concat(dataframes_list).drop_duplicates()\n",
    "        \n",
    "        sentences_with_comparator = pd.concat([df_recherche,\n",
    "          pd.DataFrame({'sentence':[' '.join(tokens_list)],\n",
    "              'from_doc':['comparateur']})]\n",
    "         ).reset_index(drop=True)\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vector_text = vectorizer.fit_transform(sentences_with_comparator['sentence'])\n",
    "        similarity = cosine_similarity(vector_text[vector_text.shape[0]-1,:],vector_text)\n",
    "        sentences_with_comparator['similarity'] = similarity[0]\n",
    "        sentences_with_comparator = sentences_with_comparator.sort_values('similarity', ascending=False)\\\n",
    "                           .reset_index(drop=True)\n",
    "        final_result = sentences_with_comparator[sentences_with_comparator['from_doc'] != 'comparateur']\n",
    "    if len(doclist) == 0:\n",
    "    \n",
    "        return final_result\n",
    "    elif len(doclist) > 0: \n",
    "        return final_result[final_result['from_doc'].isin(doclist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d9c2bec2-0c8a-4ccf-8f3b-c39f858bae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>from_doc</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, from_doc, similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtv = search_tokens(['groupe'],['girandola 2.txt'])\n",
    "wtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "22079ef2-bf34-431c-961d-92f59be07e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f8e4b48d-e9a8-4d88-9ad0-a0f7baa5193a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([\"j'ai un autre point de vue\"],\n",
    "           ).str.contains('|'.join(words_of_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "242f4847-cd43-4a56-9e31-bf5c7e48005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>from_doc</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traité de psychologie sociale</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.201223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Explication causale : un des domaines de prédi...</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.106923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>L’attribution causale se trouve donc être un ...</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.088698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>L’attribution causale se trouve donc au centre...</td>\n",
       "      <td>lomonaco 1.txt</td>\n",
       "      <td>0.074599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence        from_doc  \\\n",
       "1                       Traité de psychologie sociale  lomonaco 1.txt   \n",
       "9   Explication causale : un des domaines de prédi...  lomonaco 1.txt   \n",
       "15   L’attribution causale se trouve donc être un ...  lomonaco 1.txt   \n",
       "22  L’attribution causale se trouve donc au centre...  lomonaco 1.txt   \n",
       "\n",
       "    similarity  \n",
       "1     0.201223  \n",
       "9     0.106923  \n",
       "15    0.088698  \n",
       "22    0.074599  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        wtv[wtv['from_doc'].isin(['lomonaco 1.txt'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5661644-179b-4182-9544-d42e5a861125",
   "metadata": {},
   "source": [
    "# todo :\n",
    "construire une requette qui récupère seulement les textes où tous les mots sont présents pas seulement un d'entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65708461-9ea5-4cef-b9c8-5085732d91dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
