{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6c7873-5841-4927-ad07-c4d9c9643b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import pyArango\n",
    "import os\n",
    "from os import path\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arango import ArangoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15f5f2-be00-455f-9706-671881a903d7",
   "metadata": {},
   "source": [
    "Lecture du texte depuis le chemin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551cdde1-7d69-4e98-9c99-193778339df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        return(f.read().replace('\\n',' '))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e859a1b1-d3d1-4064-b33e-30bf440d5125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paul/projects/text explorer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.getcwd()\n",
    "dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b702e-7692-407e-81e6-40dc8b35332a",
   "metadata": {},
   "source": [
    "Liste des fichiers présents dans le dossier choisi pour l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405e5599-89c9-414b-8e90-8aa71d951494",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/home/paul/projects/text_for_app/*.{}'.format('txt'))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7132b-6ccd-4857-bb16-23c78df49815",
   "metadata": {},
   "source": [
    "# Intégrer la lecture de fichiers dans une logique de vérification des informations dans la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0639a1-7c93-4fe9-b22b-84328e7698b7",
   "metadata": {},
   "source": [
    "Obtention du nom du fichier depuis le chemin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ef6cb5-0757-4017-a3b8-d14be62a678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_from_path(path):\n",
    "    return os.path.normpath(path).split(os.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95eb266c-eca4-4c24-875a-1a3dea46015e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>doc_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/paul/projects/text_for_app/jean_blog.txt</td>\n",
       "      <td>jean_blog.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/paul/projects/text_for_app/emploi étudia...</td>\n",
       "      <td>emploi étudiant et inégalités sociales.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  \\\n",
       "0     /home/paul/projects/text_for_app/jean_blog.txt   \n",
       "1  /home/paul/projects/text_for_app/emploi étudia...   \n",
       "\n",
       "                                     doc_name  doc_number  \n",
       "0                               jean_blog.txt           0  \n",
       "1  emploi étudiant et inégalités sociales.txt           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.DataFrame({'filepath':files,\n",
    "                          'doc_name':[get_filename_from_path(filepath) for filepath in files],\n",
    "                          'doc_number':list(range(0,len(files)))})\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ea8a7-7052-4641-af64-9fea04316dff",
   "metadata": {},
   "source": [
    "Initialisation de la connection avec la base de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7232caf-3eff-4b8b-bd0e-56ba3bc44a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client for ArangoDB.\n",
    "client = ArangoClient(hosts=\"http://localhost:8529\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cb3f359-7e8e-49bf-87a4-9fd3b76a11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_db = client.db('_system', username='root',password='root')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987f104-3e32-4c55-9e8c-6ea4f499644e",
   "metadata": {},
   "source": [
    "si besoin de repartir à zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "65c6106a-66bb-47dd-a771-5881e9e203c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_db.delete_database('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bb57b-0e9e-411b-8cc1-502108436582",
   "metadata": {},
   "source": [
    "Check si la base de données existe déjà et création si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a20a9e06-ed07-4f5b-8b47-00d6041d6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sys_db.has_database('text'):\n",
    "    \n",
    "    sys_db.create_database('text')\n",
    "    db = client.db(\"text\", username=\"root\", password=\"root\")\n",
    "    graph = db.create_graph('text_explorer')\n",
    "    # création des collections\n",
    "    docs = graph.create_vertex_collection('docs')\n",
    "    sentences = graph.create_vertex_collection('sentences')\n",
    "    tokens = graph.create_vertex_collection('tokens')\n",
    "    lemmas = graph.create_vertex_collection('lemmas')\n",
    "    # création des arrêtes\n",
    "    is_from = graph.create_edge_definition(\n",
    "        edge_collection='is_from',\n",
    "        from_vertex_collections=['sentences'],\n",
    "        to_vertex_collections=['docs']\n",
    "    )\n",
    "    contracts_to = graph.create_edge_definition(\n",
    "        edge_collection='contracts_to',\n",
    "        from_vertex_collections=['tokens'],\n",
    "        to_vertex_collections=['lemmas']\n",
    "    )\n",
    "    syntagmatic_link = graph.create_edge_definition(\n",
    "        edge_collection='syntagmatic_link',\n",
    "        from_vertex_collections=['tokens'],\n",
    "        to_vertex_collections=['tokens']\n",
    "    )\n",
    "else:\n",
    "    db = client.db(\"text\", username=\"root\", password=\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8bc8a-0c90-4153-ad4c-710a4d2344b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57df3b3-4e03-4e6b-9347-a372fd5f0638",
   "metadata": {},
   "source": [
    "L'objectif maintenant est de remplir ces champs avec les données extraites depuis le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0341d2-0e8b-4363-8151-320ddbd6fb8a",
   "metadata": {},
   "source": [
    "### insertion des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "87c07d01-c6cb-431c-a936-94589f80822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_name, number, path  in zip(documents['doc_name'], documents['doc_number'], documents['filepath']):\n",
    "    docs.insert({'_key':f'doc{number}',\n",
    "                 'doc_name':doc_name,\n",
    "                 'doc_path':path,\n",
    "                 'doc_number':number,\n",
    "                 'processed':'False'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "862314c9-9e54-4297-b922-fbcffde58584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jean_blog.txt', 'emploi étudiant et inégalités sociales.txt']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_db_doclist = list(db.aql.execute('''FOR doc in docs RETURN doc.doc_name'''))\n",
    "in_db_doclist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b5745-ffc1-475f-a3f7-b8bf2e4efffe",
   "metadata": {},
   "source": [
    "Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "445a2ee3-c54b-4013-9c62-47687b08ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfbdeb-8e90-4c45-bf06-3855041d95eb",
   "metadata": {},
   "source": [
    "Traitement des fichiers par le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4464a67-236a-497a-ae38-c562907e975d",
   "metadata": {},
   "source": [
    "## se renseigner sur comment faire du traitement en batch\n",
    "    - mesurer l'empreinte mémoire de l'opération et ajuster combien de documents en même temps peuvent être traités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e4bb5a61-8314-4e96-82a3-6501a29ac10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/paul/projects/text_for_app/jean_blog.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/paul/projects/text_for_app/emploi étudia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  number\n",
       "0     /home/paul/projects/text_for_app/jean_blog.txt       0\n",
       "1  /home/paul/projects/text_for_app/emploi étudia...       1"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_to_process_df = pd.DataFrame(\n",
    "                        list(\n",
    "                            db.aql.execute('''\n",
    "                                            FOR doc in docs\n",
    "                                            FILTER doc.processed == 'False'\n",
    "                                            RETURN {path :doc.doc_path, number : doc.doc_number}\n",
    "                                            ''')\n",
    "                            )\n",
    "                        )\n",
    "texts_to_process_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf2514-5fbf-49cb-94b3-69eae39d1e95",
   "metadata": {},
   "source": [
    "### insertion des phrases\n",
    "Si nous construisons le ID sur la base de la boucle ci-dessous comment incrémenter l'ID avec des traitements batch ? \n",
    "- stocker le numéro de chaque documents dans la db \n",
    "- avant chaque insertion requêter le numéro de document le plus élevé et repartir de ce point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4b5b2158-b361-4d36-a5c4-3b841a833db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = list(nlp.pipe([get_text(path) for path in texts_to_process_df['path']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "6b8500a7-b6e3-46b3-8a5a-86f0914c7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, doc_number in zip(processed_docs,texts_to_process_df['number']):\n",
    "    for sentence_number, sentence in enumerate(doc.sents):\n",
    "        if sentence.text != ' ':\n",
    "            sentences.insert({'_key':f'doc{doc_number}sent{sentence_number}',\n",
    "                              'content':sentence.text})\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1dbfb4-6e20-4e19-b6ab-42daca6ef69b",
   "metadata": {},
   "source": [
    "Insertion des tokens et lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bca780-d91b-48bf-b25d-63d08569bc2f",
   "metadata": {},
   "source": [
    "Récupérer le vocabulaire token et lemma de chaque doc et les insérer dans la db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a93447-8583-44dd-aa24-be643f1dc85a",
   "metadata": {},
   "source": [
    "- clé = nombre arbitraire d'insertion\n",
    "- valeur = le token ou lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc2826-6fc9-4bc4-b35d-bb2a78e05eda",
   "metadata": {},
   "source": [
    "Pour insérer de nouveaux mots par la suite faire une requette sur la table des tokens / lemma et insérer ceux qui ne sont pas déjà présents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e83a71-7889-4bee-a35c-8d170d94c8a0",
   "metadata": {},
   "source": [
    "pour les relations faire une requete par phrase où l'on récupère chaque mot et sa clé associée\n",
    "- relier ensuite les mots entre eux en utilisant les clés et la modalité de cette relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7258a4-a7b8-424b-bc1c-1caed15d051e",
   "metadata": {},
   "source": [
    "Comment relier les phrases aux documents et les mots aux phrases ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0c599179-3969-4631-b23e-bc65575d5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab_tokens = []\n",
    "new_vocab_lemmas = []\n",
    "seen_tokens = set()\n",
    "seen_lemmas = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "dddac552-ed78-4afb-b78d-262874d20c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in processed_docs[1]:\n",
    "    if token.text.lower() not in seen_tokens  and not token.is_punct and not token.is_stop and not token.is_space:\n",
    "        new_vocab_tokens.append(token.text.lower())\n",
    "    seen_tokens.add(token.text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cb73e7e0-18c5-48e9-99f2-bb6574c11a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in processed_docs[1]:\n",
    "    if token.lemma_ not in seen_lemmas  and not token.is_punct and not token.is_stop and not token.is_space:\n",
    "        new_vocab_tokens.append(token.lemma_.lower())\n",
    "    seen_tokens.add(token.text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6f715-b094-4a2b-9554-54488b1f4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91509f-5d3e-42e9-991a-fd23e64499f3",
   "metadata": {},
   "source": [
    "Check si il faut commencer un indexage pour le vocabulaire ou le récupérer et poursuivre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c44e4-fb13-45cd-a5fb-a1af58d6bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(db.aql.execute(\"\"\"\n",
    "            FOR doc in tokens\n",
    "            RETURN {token :doc.token, key : doc._key}\n",
    "            \"\"\"))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "27226cf1-beb1-4b6e-b103-dbbfdd2d8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(vocab) == 0:\n",
    "        for count, token in enumerate(new_vocab_tokens):\n",
    "            tokens.insert({\"_key\":f'token{count}',\n",
    "                           \"number\":count,\n",
    "                           \"token\":token})\n",
    "else :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "690f52af-5b02-4c56-aa5b-033cd214d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_tokens_to_insert = []\n",
    "for count, token in enumerate(new_vocab_tokens):\n",
    "    dict_list_tokens_to_insert.append({\"_key\":f'token{count}',\n",
    "                                       'token':token})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91a795-19b8-4c05-9b8a-6165893d14bc",
   "metadata": {},
   "source": [
    "# faire un bulk import pour toutes les opérations \n",
    "- finir d'importer les lemmas\n",
    "- faire un import des liens entre les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3ff7f843-3085-42d9-88e0-64e51d44a122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "994daafe-1a48-4664-8ba3-f087a5f55c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9576508d-7c71-4c03-89ed-44da60600268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f7a624ed-a7ad-4b19-bdd9-252ecafb3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with db.begin_batch_execution() as batch_token:\n",
    "    for count, token in enumerate(new_vocab_tokens):\n",
    "            tokens.insert({\"_key\":f'token{count}',\n",
    "                           \"number\":count,\n",
    "                           \"token\":token})\n",
    "    batch_token.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "30317430-cd04-4ddf-9ca8-a68977f48bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'token':new_vocab_tokens,\n",
    "              '_key':list(range(0,len(new_vocab_tokens)))}).to_csv('vocab_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff390f51-5568-4446-a22a-ece9666f6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in processed_docs:\n",
    "    for count, sentence in enumerate(doc.sents):\n",
    "        print(count, sentence.text, sentence.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "58ccd0ef-ded3-42fe-9b5d-e479ad3848ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 71 \\x0c'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57635bce-3f06-43ad-99bc-b32ddaed1c52",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ce844-4cad-49b8-86c0-835894eeee0e",
   "metadata": {},
   "source": [
    "Extraction d'une forme tabulaire de la structure syntagmatique.\n",
    "  > Le processus est itéré sur l'ensemble des phrases du document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48820f5e-2670-4abc-869c-acddbac58d55",
   "metadata": {},
   "source": [
    "on obtient une liste de dataframes contenant la structure syntagmatique pour chaque phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bebd5068-1e89-4cd1-887d-c4b6ba162a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dependancy_df_list(processed_text):\n",
    "    df_list = []\n",
    "    for sentence in processed_text.sents:\n",
    "        token_text, token_dep, token_head_text, token_head_pos = [], [], [], []\n",
    "        for token in sentence:\n",
    "            if not token.is_punct and not token.is_stop and not token.is_space:\n",
    "                token_text.append(token.text)\n",
    "                token_dep.append(token.dep_), \n",
    "                token_head_text.append(token.head.text), \n",
    "                token_head_pos.append( token.head.pos_)\n",
    "        df = pd.DataFrame({'token':token_text,\n",
    "                           'dep':token_dep,\n",
    "                           'head_text':token_head_text,\n",
    "                           'head_pos':token_head_pos})    \n",
    "        if not df.empty:\n",
    "            df_list.append(df)\n",
    "        else:\n",
    "            pass\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd14dcb0-c6fd-46bd-b8ad-7ef0efdec824",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1_processed = nlp(get_text(documents['filepath'][0]))\n",
    "file_2_processed = nlp(get_text(documents['filepath'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71c5fc2f-1b44-4cc5-941c-c8529675dc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_text</th>\n",
       "      <th>head_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faire</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>vais</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inutilement</td>\n",
       "      <td>advmod</td>\n",
       "      <td>faire</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>durer</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>faire</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suspense</td>\n",
       "      <td>obj</td>\n",
       "      <td>durer</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>réponse</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>oui</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oui</td>\n",
       "      <td>parataxis</td>\n",
       "      <td>vais</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token        dep head_text head_pos\n",
       "0        faire      xcomp      vais     VERB\n",
       "1  inutilement     advmod     faire     VERB\n",
       "2        durer      xcomp     faire     VERB\n",
       "3     suspense        obj     durer     VERB\n",
       "4      réponse      nsubj       oui      ADV\n",
       "5          oui  parataxis      vais     VERB"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dependancy_df_list(file_1_processed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba3d25-2d6d-4642-b786-ad4c943e014d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
