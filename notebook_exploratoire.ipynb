{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6c7873-5841-4927-ad07-c4d9c9643b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import pyArango\n",
    "import os\n",
    "from os import path\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from arango import ArangoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ea8a7-7052-4641-af64-9fea04316dff",
   "metadata": {},
   "source": [
    "Initialisation de la connection avec la base de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7232caf-3eff-4b8b-bd0e-56ba3bc44a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client for ArangoDB.\n",
    "client = ArangoClient(hosts=\"http://localhost:8529\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb3f359-7e8e-49bf-87a4-9fd3b76a11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_db = client.db('_system', username='root',password='root')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987f104-3e32-4c55-9e8c-6ea4f499644e",
   "metadata": {},
   "source": [
    "si besoin de repartir à zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "65c6106a-66bb-47dd-a771-5881e9e203c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_db.delete_database('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bb57b-0e9e-411b-8cc1-502108436582",
   "metadata": {},
   "source": [
    "Check si la base de données existe déjà et création si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a20a9e06-ed07-4f5b-8b47-00d6041d6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sys_db.has_database('text'):\n",
    "    \n",
    "    sys_db.create_database('text')\n",
    "    db = client.db(\"text\", username=\"root\", password=\"root\")\n",
    "    graph = db.create_graph('text_explorer')\n",
    "    # création des collections\n",
    "    docs = graph.create_vertex_collection('docs')\n",
    "    sentences = graph.create_vertex_collection('sentences')\n",
    "    tokens = graph.create_vertex_collection('tokens')\n",
    "    lemmas = graph.create_vertex_collection('lemmas')\n",
    "    # création des arrêtes\n",
    "    is_from = graph.create_edge_definition(\n",
    "        edge_collection='is_from',\n",
    "        from_vertex_collections=['sentences','tokens'],\n",
    "        to_vertex_collections=['docs','sentences']\n",
    "    )\n",
    "    contracts_to = graph.create_edge_definition(\n",
    "        edge_collection='contracts_to',\n",
    "        from_vertex_collections=['tokens'],\n",
    "        to_vertex_collections=['lemmas']\n",
    "    )\n",
    "    syntagmatic_link = graph.create_edge_definition(\n",
    "        edge_collection='syntagmatic_link',\n",
    "        from_vertex_collections=['tokens'],\n",
    "        to_vertex_collections=['tokens']\n",
    "    )\n",
    "else:\n",
    "    db = client.db(\"text\", username=\"root\", password=\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57df3b3-4e03-4e6b-9347-a372fd5f0638",
   "metadata": {},
   "source": [
    "L'objectif maintenant est de remplir ces champs avec les données extraites depuis le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e35a3-c60c-44eb-ab33-aef3f046f55b",
   "metadata": {},
   "source": [
    "Récupération des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "551cdde1-7d69-4e98-9c99-193778339df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        return(f.read().replace('\\n',' '))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e859a1b1-d3d1-4064-b33e-30bf440d5125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paul/projects/text explorer'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.getcwd()\n",
    "dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d540b4d-726e-4254-bf5a-719c699d4251",
   "metadata": {},
   "source": [
    "Liste des fichiers présents dans le dossier choisi pour l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "405e5599-89c9-414b-8e90-8aa71d951494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/paul/projects/text_for_app/jean_blog.txt',\n",
       " '/home/paul/projects/text_for_app/emploi étudiant et inégalités sociales.txt']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('/home/paul/projects/text_for_app/*.{}'.format('txt'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e6ef6cb5-0757-4017-a3b8-d14be62a678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_from_path(path):\n",
    "    return os.path.normpath(path).split(os.sep)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "490f3921-3654-4653-a4c4-3b59bee566a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>doc_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/paul/projects/text_for_app/jean_blog.txt</td>\n",
       "      <td>jean_blog.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/paul/projects/text_for_app/emploi étudia...</td>\n",
       "      <td>emploi étudiant et inégalités sociales.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  \\\n",
       "0     /home/paul/projects/text_for_app/jean_blog.txt   \n",
       "1  /home/paul/projects/text_for_app/emploi étudia...   \n",
       "\n",
       "                                     doc_name  doc_number  \n",
       "0                               jean_blog.txt           0  \n",
       "1  emploi étudiant et inégalités sociales.txt           1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.DataFrame({'filepath':files,\n",
    "                          'doc_name':[get_filename_from_path(filepath) for filepath in files],\n",
    "                          'doc_number':list(range(0,len(files)))})\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "11549c59-b792-4492-b26b-be12ac62163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_docs(documents_found):\n",
    "    in_db_doclist = pd.DataFrame(list(db.aql.execute('''FOR doc in docs RETURN doc''')))\n",
    "    if in_db_doclist.shape == (0,0):\n",
    "        pass\n",
    "    else :\n",
    "        documents_found = documents_found[~documents_found['doc_name'].isin(in_db_doclist['doc_name'])]\n",
    "        last_doc_number = in_db_doclist['doc_number'].max()\n",
    "        documents_found['doc_number'] = documents_found['doc_number'] + last_doc_number + 1\n",
    "    \n",
    "    dict_list_documents_to_insert = []\n",
    "    for doc_name, number, path  in zip(documents_found['doc_name'], documents_found['doc_number'], documents_found['filepath']):\n",
    "        dict_list_documents_to_insert.append({'_key':f'doc{number}',\n",
    "                                                'doc_name':doc_name,\n",
    "                                                'doc_path':path,\n",
    "                                                'doc_number':number,\n",
    "                                                'processed':'False'})\n",
    "    db.collection('docs').import_bulk(dict_list_documents_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "72c053c1-169a-443b-a1c3-1d55fdf44a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_docs(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b5745-ffc1-475f-a3f7-b8bf2e4efffe",
   "metadata": {},
   "source": [
    "# Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "445a2ee3-c54b-4013-9c62-47687b08ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfbdeb-8e90-4c45-bf06-3855041d95eb",
   "metadata": {},
   "source": [
    "Traitement des fichiers par le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4464a67-236a-497a-ae38-c562907e975d",
   "metadata": {},
   "source": [
    "## se renseigner sur comment faire du traitement en batch\n",
    "    - mesurer l'empreinte mémoire de l'opération et ajuster combien de documents en même temps peuvent être traités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f4986fa9-3661-4abb-bfe8-9559a3e21789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/paul/projects/text_for_app/jean_blog.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/paul/projects/text_for_app/emploi étudia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  number\n",
       "0     /home/paul/projects/text_for_app/jean_blog.txt       0\n",
       "1  /home/paul/projects/text_for_app/emploi étudia...       1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_to_process_df = pd.DataFrame(\n",
    "                        list(\n",
    "                            db.aql.execute('''\n",
    "                                            FOR doc in docs\n",
    "                                            FILTER doc.processed == 'False'\n",
    "                                            RETURN {path :doc.doc_path, number : doc.doc_number}\n",
    "                                            ''')\n",
    "                            )\n",
    "                        )\n",
    "texts_to_process_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026546dd-8c66-4427-a9ac-c4f5acfcaaec",
   "metadata": {},
   "source": [
    "Voir l'empreinte mémoire de l'opération. Découper l'output des textes à traiter pour ne pas tout fournir direction à l'opération ci dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ff4777cf-abc3-492d-b1f5-87ee8d14862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = list(nlp.pipe([get_text(path) for path in texts_to_process_df['path']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ee3a1af2-f9ac-404b-b860-3d8f34cc9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sentences(processed_doc, doc_number):\n",
    "    dict_sentences_to_insert = []\n",
    "    for sentence_number, sentence in enumerate(processed_doc.sents):\n",
    "        if sentence.text != ' ':\n",
    "            dict_sentences_to_insert.append({'_key':f'doc{doc_number}sent{sentence_number}',\n",
    "                                             'content':sentence.text})\n",
    "        else:\n",
    "            pass\n",
    "    db.collection('sentences').import_bulk(dict_sentences_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a0a7c42c-c224-49ac-8b25-307526168618",
   "metadata": {},
   "outputs": [],
   "source": [
    "for processed_text, doc_number in zip(processed_docs,texts_to_process_df['number']):\n",
    "    insert_sentences(processed_text,doc_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1dbfb4-6e20-4e19-b6ab-42daca6ef69b",
   "metadata": {},
   "source": [
    "Insertion des tokens et lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bca780-d91b-48bf-b25d-63d08569bc2f",
   "metadata": {},
   "source": [
    "Récupérer le vocabulaire token et lemma de chaque doc et les insérer dans la db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a93447-8583-44dd-aa24-be643f1dc85a",
   "metadata": {},
   "source": [
    "- clé = nombre arbitraire d'insertion\n",
    "- valeur = le token ou lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc2826-6fc9-4bc4-b35d-bb2a78e05eda",
   "metadata": {},
   "source": [
    "Pour insérer de nouveaux mots par la suite faire une requette sur la table des tokens / lemma et insérer ceux qui ne sont pas déjà présents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e83a71-7889-4bee-a35c-8d170d94c8a0",
   "metadata": {},
   "source": [
    "pour les relations faire une requete par phrase où l'on récupère chaque mot et sa clé associée\n",
    "- relier ensuite les mots entre eux en utilisant les clés et la modalité de cette relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7258a4-a7b8-424b-bc1c-1caed15d051e",
   "metadata": {},
   "source": [
    "Comment relier les phrases aux documents et les mots aux phrases ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6d4cd-cceb-4dc3-8ccf-032e66685e96",
   "metadata": {},
   "source": [
    "### Extraction des correspondances lemmes / tokens depuis le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d797687f-5d8b-4104-9809-e09303ba3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_table_from_text(processed_text):\n",
    "    tokens, lemmas = [], []\n",
    "    for token in processed_text:\n",
    "        if not token.is_punct and not token.is_stop and not token.is_space and not token.is_digit:\n",
    "            tokens.append(token.text.lower())\n",
    "            lemmas.append(token.lemma_.lower())\n",
    "    vocab_table = pd.DataFrame({'token':tokens,\n",
    "                                'lemma':lemmas})\n",
    "    return vocab_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a14c80-f90a-48f5-acfe-917848501460",
   "metadata": {},
   "source": [
    "### Construction de deux tables contenant les occurences uniques des lemmes et tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dc915556-a603-44c0-a23f-492dd8e59ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vocabulary(token_lemma_table,word_type):\n",
    "    return(token_lemma_table[word_type].drop_duplicates().reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff11335-c85b-4560-b893-014494f2ac57",
   "metadata": {},
   "source": [
    "### Extraction du vocabulaire existant depuis la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c9b780fb-9719-456f-8f9c-b342d80bdeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_in_db():\n",
    "    vocab_tokens_from_db = pd.DataFrame(\n",
    "        list(db.aql.execute(\"\"\"\n",
    "            FOR doc in tokens\n",
    "            RETURN {word :doc.token, key : doc._key}\n",
    "            \"\"\"))\n",
    "        )\n",
    "        \n",
    "    vocab_lemmas_from_db = pd.DataFrame(\n",
    "        list(db.aql.execute(\"\"\"\n",
    "            FOR doc in lemmas\n",
    "            RETURN {word :doc.lemma, key : doc._key}\n",
    "            \"\"\"))\n",
    "        )\n",
    "    return vocab_tokens_from_db, vocab_lemmas_from_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d72934-838b-40a3-a63a-e78fad879ef3",
   "metadata": {},
   "source": [
    "### Comparaison du vocabulaire extrait du texte avec celui déjà contenu dans la db\n",
    "- On ne rajoute que les instances jamais vues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "930abf54-e511-471a-818a-d7264db99b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_new_vocab(vocab_from_text,vocab_from_db):\n",
    "    new_vocab = vocab_from_text[~vocab_from_text.isin(vocab_from_db['word'])].reset_index(drop=True)\n",
    "    return new_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c910ef-1fb6-452c-ad1a-7c577befb09b",
   "metadata": {},
   "source": [
    "A refactoriser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b1b90650-55f2-4215-86bb-04abb602f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vocab_to_db(processed_text):\n",
    "    token_to_lemma_table = get_vocab_table_from_text(processed_text)\n",
    "    \n",
    "    text_tokens_series = unique_vocabulary(token_to_lemma_table,'token')\n",
    "    text_lemmas_series = unique_vocabulary(token_to_lemma_table,'lemma')\n",
    "    \n",
    "    tokens_from_db, lemmas_from_db = get_vocab_in_db()\n",
    "    \n",
    "    if tokens_from_db.shape == (0,0):\n",
    "        dict_list_tokens_to_insert = []\n",
    "        for index, token in zip(text_tokens_series.index,text_tokens_series.values):\n",
    "            dict_list_tokens_to_insert.append({\"_key\":f'token{index}',\n",
    "                                               'token':token})\n",
    "        db.collection('tokens').import_bulk(dict_list_tokens_to_insert)\n",
    "\n",
    "        dict_list_lemmas_to_insert = []\n",
    "        for index, lemma in zip(text_lemmas_series.index,text_lemmas_series.values):\n",
    "            dict_list_lemmas_to_insert.append({\"_key\":f'lemma{index}',\n",
    "                                               'lemma':lemma})\n",
    "        db.collection('lemmas').import_bulk(dict_list_lemmas_to_insert)\n",
    "\n",
    "    else :\n",
    "        new_vocab_tokens = keep_only_new_vocab(text_tokens_series,tokens_from_db)\n",
    "        new_vocab_lemmas = keep_only_new_vocab(text_lemmas_series,lemmas_from_db)\n",
    "\n",
    "        new_vocab_tokens.index = new_vocab_tokens.index + tokens_from_db.shape[0] + 1\n",
    "        new_vocab_lemmas.index = new_vocab_lemmas.index + lemmas_from_db.shape[0] + 1\n",
    "\n",
    "        dict_list_tokens_to_insert = []\n",
    "        for index, token in zip(new_vocab_tokens.index,new_vocab_tokens.values):\n",
    "            dict_list_tokens_to_insert.append({\"_key\":f'token{index}',\n",
    "                                               'token':token})\n",
    "        db.collection('tokens').import_bulk(dict_list_tokens_to_insert)\n",
    "\n",
    "        dict_list_lemmas_to_insert = []\n",
    "        for index, lemma in zip(new_vocab_lemmas.index,new_vocab_lemmas.values):\n",
    "            dict_list_lemmas_to_insert.append({\"_key\":f'lemma{index}',\n",
    "                                               'lemma':lemma})\n",
    "        db.collection('lemmas').import_bulk(dict_list_lemmas_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c0d78688-1a0f-4426-97eb-335eac3d9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_vocab_to_db(processed_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d329c5a5-53a2-4ec6-8677-310480a98a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_vocab_to_db(processed_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7af4c-274a-4919-a6f0-e75cf0cfd109",
   "metadata": {},
   "source": [
    "### Relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0bcc3-81ca-4f01-831c-5cb82d7fdfa3",
   "metadata": {},
   "source": [
    "Les 3 types de relations dans le graphe, ce qu'elles connectent et ce qu'elles contiennent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71851b-a31c-4225-9668-76d7ac2e711a",
   "metadata": {},
   "source": [
    "phrases aux docs :\n",
    "- faire un call sur les phrases de la db \n",
    "- clé from = la clé de chaque phrase \n",
    "- clé to = la première partie de la clé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "4cb76a79-fe26-400f-9305-6048d0bdcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_keys = pd.Series(list(db.aql.execute('''\n",
    "                        FOR doc in sentences\n",
    "                        return doc._key\n",
    "                        ''')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "cca4018b-bf4d-410e-b676-364d9883dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_number_for_sentences = sentences_keys.str.extract('(\\d+)')[0]\n",
    "sentences_number = sentences_keys.str.extract('\\D+\\d+\\D+(\\d+)')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "802c89c6-0961-4bfa-b0e1-595b07c4795b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       doc0sent0\n",
       "1       doc0sent1\n",
       "2      doc0sent11\n",
       "3      doc0sent12\n",
       "4      doc0sent13\n",
       "          ...    \n",
       "531    doc1sent95\n",
       "532    doc1sent96\n",
       "533    doc1sent97\n",
       "534    doc1sent98\n",
       "535    doc1sent99\n",
       "Length: 536, dtype: object"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb3654-3ab1-42c0-8aab-098ea84b82f3",
   "metadata": {},
   "source": [
    "is_from :\n",
    "- les phrases aux documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d0a652de-f45f-4161-874d-266cd216b383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': False,\n",
       " 'created': 536,\n",
       " 'errors': 0,\n",
       " 'empty': 0,\n",
       " 'updated': 0,\n",
       " 'ignored': 0,\n",
       " 'details': []}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_is_from_sent_doc_to_insert = []\n",
    "for sentence_key, doc_number, sentence_number in zip(sentences_keys.values,doc_number_for_sentences,sentences_number.values):\n",
    "    dict_is_from_sent_doc_to_insert.append({'_from':sentence_key,\n",
    "                                            '_to':f'doc{doc_number}',\n",
    "                                            'sentence_number': sentence_number})\n",
    "db.collection('is_from').import_bulk(dict_is_from_sent_doc_to_insert,\n",
    "                                     from_prefix='sentences/',\n",
    "                                     to_prefix='docs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931051c-e39f-4a20-9b2e-672b9152dd57",
   "metadata": {},
   "source": [
    "is_from :\n",
    "- les tokens aux phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72783cc-9582-40cb-b095-f33d754898e5",
   "metadata": {},
   "source": [
    "Extraction d'une forme tabulaire de la structure syntagmatique.\n",
    "  - Le processus est itéré sur l'ensemble des phrases du document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "89cb8bf6-5187-455a-bd20-cb39ca0d0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dependancy_df(processed_text):\n",
    "    token_text, token_dep, token_head_text, token_head_pos, sentence_number = [], [], [], [],[]\n",
    "\n",
    "    for count, sentence in enumerate(processed_text.sents):\n",
    "        for token in sentence:\n",
    "            if not token.is_punct and not token.is_stop and not token.is_space and not token.is_digit:\n",
    "                token_text.append(token.text)\n",
    "                token_dep.append(token.dep_), \n",
    "                token_head_text.append(token.head.text), \n",
    "                token_head_pos.append( token.head.pos_)\n",
    "                sentence_number.append(count)\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame({'token':token_text,\n",
    "                       'dep':token_dep,\n",
    "                       'head_text':token_head_text,\n",
    "                       'head_pos':token_head_pos,\n",
    "                       'sentence_number':sentence_number})   \n",
    "    df = df[df['head_pos']!=\"SPACE\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "d0b610dd-85a7-4c19-a3bf-59006d2358f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependancy_df = create_dependancy_df(processed_docs[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "1bed463d-028a-49e7-9c9f-c5e1e54c13f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_text</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>sentence_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAIRN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>CAIRN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MATIERES</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>MATIERES</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REFLEXION</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>REFLEXION</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMPLOI</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>EMPLOI</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ETUDIANT</td>\n",
       "      <td>amod</td>\n",
       "      <td>EMPLOI</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>Europe</td>\n",
       "      <td>nmod</td>\n",
       "      <td>normes</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>Travail</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>Emploi</td>\n",
       "      <td>conj</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>juillet</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>p.</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5426 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          token   dep  head_text head_pos  sentence_number\n",
       "0         CAIRN  ROOT      CAIRN    PROPN                0\n",
       "2      MATIERES  ROOT   MATIERES     NOUN                2\n",
       "3     REFLEXION  ROOT  REFLEXION     NOUN                3\n",
       "4        EMPLOI  ROOT     EMPLOI     NOUN                4\n",
       "5      ETUDIANT  amod     EMPLOI     NOUN                4\n",
       "...         ...   ...        ...      ...              ...\n",
       "5465     Europe  nmod     normes     NOUN              537\n",
       "5466    Travail  ROOT    Travail     NOUN              538\n",
       "5467     Emploi  conj    Travail     NOUN              538\n",
       "5468    juillet  nmod    Travail     NOUN              538\n",
       "5469         p.  nmod    Travail     NOUN              538\n",
       "\n",
       "[5426 rows x 5 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependancy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "26d92d50-945c-4e5f-806e-d55f4ffbd604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faire</td>\n",
       "      <td>token0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inutilement</td>\n",
       "      <td>token1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>durer</td>\n",
       "      <td>token2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suspense</td>\n",
       "      <td>token3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>réponse</td>\n",
       "      <td>token4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>florence</td>\n",
       "      <td>token2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>lefresne</td>\n",
       "      <td>token2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>vecteurs</td>\n",
       "      <td>token2858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>structurelle</td>\n",
       "      <td>token2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>juillet</td>\n",
       "      <td>token2860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word        key\n",
       "0            faire     token0\n",
       "1      inutilement     token1\n",
       "2            durer     token2\n",
       "3         suspense     token3\n",
       "4          réponse     token4\n",
       "...            ...        ...\n",
       "2855      florence  token2856\n",
       "2856      lefresne  token2857\n",
       "2857      vecteurs  token2858\n",
       "2858  structurelle  token2859\n",
       "2859       juillet  token2860\n",
       "\n",
       "[2860 rows x 2 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_table_tokens_in_db = get_vocab_in_db()[0]\n",
    "vocab_table_tokens_in_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "50793339-0b3e-4476-8d16-46076f9db2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': False,\n",
       " 'created': 0,\n",
       " 'errors': 0,\n",
       " 'empty': 0,\n",
       " 'updated': 0,\n",
       " 'ignored': 0,\n",
       " 'details': []}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_is_from_sent_token_to_insert = []\n",
    "for token_key,sentence_number in zip(token_from_sentence_table['key'],token_from_sentence_table['sentence_number'] ):\n",
    "    dict_is_from_sent_doc_to_insert.append({'_from':token_key,\n",
    "                                            '_to':f'sentence{sentence_number}'})\n",
    "db.collection('is_from').import_bulk(dict_is_from_sent_token_to_insert,\n",
    "                                     from_prefix='tokens/',\n",
    "                                     to_prefix='sentences/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17299a75-99a9-4815-85a3-c371481f08fc",
   "metadata": {},
   "source": [
    "syntagmatic_link :\n",
    "- les tokens aux tokens \n",
    "    - le type de relation grammaticale\n",
    "    - l'ID de la phrase contenant cette relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f7c3175b-9cc1-49d0-b5df-8669b2ddc897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_text</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>sentence_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAIRN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>CAIRN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MATIERES</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>MATIERES</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REFLEXION</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>REFLEXION</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMPLOI</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>EMPLOI</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ETUDIANT</td>\n",
       "      <td>amod</td>\n",
       "      <td>EMPLOI</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>Europe</td>\n",
       "      <td>nmod</td>\n",
       "      <td>normes</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>Travail</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>Emploi</td>\n",
       "      <td>conj</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>juillet</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>p.</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Travail</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5426 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          token   dep  head_text head_pos  sentence_number\n",
       "0         CAIRN  ROOT      CAIRN    PROPN                0\n",
       "2      MATIERES  ROOT   MATIERES     NOUN                2\n",
       "3     REFLEXION  ROOT  REFLEXION     NOUN                3\n",
       "4        EMPLOI  ROOT     EMPLOI     NOUN                4\n",
       "5      ETUDIANT  amod     EMPLOI     NOUN                4\n",
       "...         ...   ...        ...      ...              ...\n",
       "5465     Europe  nmod     normes     NOUN              537\n",
       "5466    Travail  ROOT    Travail     NOUN              538\n",
       "5467     Emploi  conj    Travail     NOUN              538\n",
       "5468    juillet  nmod    Travail     NOUN              538\n",
       "5469         p.  nmod    Travail     NOUN              538\n",
       "\n",
       "[5426 rows x 5 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependancy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b1222-3b8b-417c-b2d2-fe3821c30601",
   "metadata": {},
   "source": [
    "Merge des tokens avec les id correspondants dans la db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8ed2ca4f-6c38-4ad3-ac55-b7cff909b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_from_sentence_table = dependancy_df.merge(vocab_table_tokens_in_db, \n",
    "                                                        left_on='token', \n",
    "                                                        right_on='word')\\\n",
    "                                                        .rename(columns={'key':'token_key'})\\\n",
    "                                                        .drop('word',axis=1)\n",
    "\n",
    "dependancy_table_for_insert = token_from_sentence_table.merge(vocab_table_tokens_in_db,\n",
    "                                                        left_on='head_text',\n",
    "                                                        right_on='word')\\\n",
    "                                                        .rename(columns={'key':'head_text_key'})\\\n",
    "                                                        .drop('word',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "14bc159a-02d4-430d-b4b9-bcc7865282d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_text</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>token_key</th>\n",
       "      <th>head_text_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>|</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>|</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>8</td>\n",
       "      <td>token106</td>\n",
       "      <td>token106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>fixed</td>\n",
       "      <td>|</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>186</td>\n",
       "      <td>token1149</td>\n",
       "      <td>token106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g</td>\n",
       "      <td>fixed</td>\n",
       "      <td>|</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>186</td>\n",
       "      <td>token1117</td>\n",
       "      <td>token106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>|</td>\n",
       "      <td>det</td>\n",
       "      <td>pages</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>11</td>\n",
       "      <td>token106</td>\n",
       "      <td>token112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>|</td>\n",
       "      <td>dep</td>\n",
       "      <td>a1qui</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>193</td>\n",
       "      <td>token106</td>\n",
       "      <td>token1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>euphémiser</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>euphémiser</td>\n",
       "      <td>VERB</td>\n",
       "      <td>529</td>\n",
       "      <td>token2836</td>\n",
       "      <td>token2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>réalité</td>\n",
       "      <td>obj</td>\n",
       "      <td>euphémiser</td>\n",
       "      <td>VERB</td>\n",
       "      <td>529</td>\n",
       "      <td>token2837</td>\n",
       "      <td>token2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>mobilisation</td>\n",
       "      <td>nmod</td>\n",
       "      <td>régime</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>530</td>\n",
       "      <td>token2840</td>\n",
       "      <td>token2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>salariale</td>\n",
       "      <td>amod</td>\n",
       "      <td>mobilisation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>530</td>\n",
       "      <td>token2841</td>\n",
       "      <td>token2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>collective</td>\n",
       "      <td>amod</td>\n",
       "      <td>action</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>531</td>\n",
       "      <td>token2845</td>\n",
       "      <td>token2606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3921 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             token    dep     head_text head_pos  sentence_number  token_key  \\\n",
       "0                |   ROOT             |     NOUN                8   token106   \n",
       "1                s  fixed             |    PUNCT              186  token1149   \n",
       "2                g  fixed             |    PUNCT              186  token1117   \n",
       "3                |    det         pages     NOUN               11   token106   \n",
       "4                |    dep         a1qui    PROPN              193   token106   \n",
       "...            ...    ...           ...      ...              ...        ...   \n",
       "3916    euphémiser   ROOT    euphémiser     VERB              529  token2836   \n",
       "3917       réalité    obj    euphémiser     VERB              529  token2837   \n",
       "3918  mobilisation   nmod        régime     NOUN              530  token2840   \n",
       "3919     salariale   amod  mobilisation     NOUN              530  token2841   \n",
       "3920    collective   amod        action     NOUN              531  token2845   \n",
       "\n",
       "     head_text_key  \n",
       "0         token106  \n",
       "1         token106  \n",
       "2         token106  \n",
       "3         token112  \n",
       "4        token1208  \n",
       "...            ...  \n",
       "3916     token2836  \n",
       "3917     token2836  \n",
       "3918     token2839  \n",
       "3919     token2840  \n",
       "3920     token2606  \n",
       "\n",
       "[3921 rows x 7 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependancy_table_for_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "cd450742-8fb0-4608-9f00-51d12f615349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': False,\n",
       " 'created': 3921,\n",
       " 'errors': 0,\n",
       " 'empty': 0,\n",
       " 'updated': 0,\n",
       " 'ignored': 0,\n",
       " 'details': []}"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_syntagmatic_link_to_insert = []\n",
    "for head_text_key, token_key, dep_relation, head_pos_tag, sentence_number in zip(dependancy_table_for_insert['head_text_key'],\n",
    "                                                                                 dependancy_table_for_insert['token_key'],\n",
    "                                                                                 dependancy_table_for_insert['dep'],\n",
    "                                                                                 dependancy_table_for_insert['head_pos'],\n",
    "                                                                                 dependancy_table_for_insert['sentence_number']):\n",
    "    dict_syntagmatic_link_to_insert.append({'_from':head_text_key,\n",
    "                                            '_to':token_key,\n",
    "                                            'dep_relation':dep_relation,\n",
    "                                            'head_pos_tag':head_pos_tag,\n",
    "                                            'from_sentence_number':sentence_number})\n",
    "db.collection('syntagmatic_link').import_bulk(dict_syntagmatic_link_to_insert,\n",
    "                                             from_prefix='tokens/',\n",
    "                                             to_prefix='tokens/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93900680-0645-474c-9a78-13fc34cf7166",
   "metadata": {},
   "source": [
    "contracts_to :\n",
    "- Les tokens aux lemmes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57635bce-3f06-43ad-99bc-b32ddaed1c52",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8533de3-3f27-489e-af73-43e3593715f8",
   "metadata": {},
   "source": [
    "# TODO :\n",
    "- Insérer une logique de check database / non répétition des insertions lors de l'insertion de nouvelles phrases\n",
    "- Assigner dans is_from entre les mots et les phrases la clé de la phrase (doc0sent20)\n",
    "- connecter les lemmes avec les tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
